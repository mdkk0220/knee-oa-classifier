# scripts/compare_knees_confidence.py
import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import numpy as np
from pathlib import Path

from src.explain.gradcam import GradCAM
from src.explain.viz_utils import overlay_heatmap, save_fig_grid


# -------------------------------------------------
# âœ… 1. ResNet50KL êµ¬ì¡° ì§ì ‘ ì •ì˜ (í•™ìŠµ ë‹¹ì‹œì™€ ë™ì¼)
# -------------------------------------------------
class ResNet50KL(nn.Module):
    def __init__(self, pretrained=False, num_classes=5):
        super().__init__()
        self.backbone = models.resnet50(weights='IMAGENET1K_V2' if pretrained else None)
        self.backbone.fc = nn.Identity()  # ë§ˆì§€ë§‰ FC ì œê±°
        self.fc = nn.Sequential(
            nn.BatchNorm1d(2048),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(2048, num_classes)
        )

    def forward(self, x):
        x = self.backbone(x)
        return self.fc(x)


# -------------------------------------------------
# âœ… 2. í•™ìŠµëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
# -------------------------------------------------
def build_resnet50_trained(weight_path="outputs/resnet50_finetune_combined/model_best.pth"):
    model = ResNet50KL(pretrained=False, num_classes=5)
    state_dict = torch.load(weight_path, map_location="cpu")

    # prefix ì •ë¦¬
    new_state_dict = {}
    for k, v in state_dict.items():
        new_key = k.replace("module.", "").replace("backbone.", "")
        new_state_dict[new_key] = v

    missing, unexpected = model.load_state_dict(new_state_dict, strict=False)
    print(f"âœ… Loading trained model from {weight_path}")
    print(f"â„¹ï¸ Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")

    model.eval()
    return model


# -------------------------------------------------
# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
# -------------------------------------------------
TR = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225)),
])


# -------------------------------------------------
# 4. ì¢Œìš° ë¬´ë¦ ë¹„êµ + í™•ì‹ ë„ ë¶„ì„
# -------------------------------------------------
def main():
    left_path = "data/processed/train/2/9002411L.png"
    right_path = "data/processed/train/2/9002411R.png"
    out_path = "outputs/vis/week5/compare_knees_conf.png"
    Path(out_path).parent.mkdir(parents=True, exist_ok=True)

    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        left_img = Image.open(left_path).convert("RGB")
        right_img = Image.open(right_path).convert("RGB")
    except FileNotFoundError:
        print("âŒ ì™¼ìª½ ë˜ëŠ” ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    left_x = TR(left_img).unsqueeze(0)
    right_x = TR(right_img).unsqueeze(0)

    model = build_resnet50_trained("outputs/resnet50_finetune_combined/model_best.pth")
    target_layer = model.backbone.layer4[-1]
    cam = GradCAM(model.backbone, target_layer)

    def predict_with_conf(x):
        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)
            conf, pred = probs.max(dim=1)
        cam_map, _ = cam(x)
        return pred.item(), conf.item(), cam_map

    left_pred, left_conf, left_cam = predict_with_conf(left_x)
    right_pred, right_conf, right_cam = predict_with_conf(right_x)

    # í™•ì‹ ë„ ë“±ê¸‰
    def confidence_mark(conf):
        if conf >= 0.8:
            return "ì‹ ë¢° ë†’ìŒ"
        elif conf >= 0.6:
            return "ì¤‘ê°„ (ì˜ì‹¬ ì˜ˆì¸¡)"
        else:
            return "ë‚®ìŒ (ì¬ê²€í†  í•„ìš”)"

    left_mark = confidence_mark(left_conf)
    right_mark = confidence_mark(right_conf)

    # ë¹„êµ ê²°ê³¼
    if left_pred > right_pred:
        compare_text = "ì™¼ìª½ ë¬´ë¦ì´ ë” ì†ìƒëœ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
    elif left_pred < right_pred:
        compare_text = "ì˜¤ë¥¸ìª½ ë¬´ë¦ì´ ë” ì†ìƒëœ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
    else:
        compare_text = "ì–‘ìª½ ë¬´ë¦ì˜ ì†ìƒ ì •ë„ê°€ ë¹„ìŠ·í•˜ê²Œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."

    # ì½˜ì†” ì¶œë ¥
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("ğŸ“Š ì¢Œìš° ë¬´ë¦ ë¹„êµ ê²°ê³¼")
    print(f"ì™¼ìª½ ì˜ˆì¸¡ ë“±ê¸‰: {left_pred} (í™•ì‹ ë„: {left_conf:.2f}) â†’ {left_mark}")
    print(f"ì˜¤ë¥¸ìª½ ì˜ˆì¸¡ ë“±ê¸‰: {right_pred} (í™•ì‹ ë„: {right_conf:.2f}) â†’ {right_mark}")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"ğŸ‘‰ {compare_text}")
    print(f"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥: {out_path}")

    # ì‹œê°í™” ì €ì¥
    save_fig_grid(
        [
            overlay_heatmap(np.array(left_img.resize((224, 224))), left_cam.numpy()),
            overlay_heatmap(np.array(right_img.resize((224, 224))), right_cam.numpy()),
        ],
        [
            f"Left Knee (KL {left_pred}, conf {left_conf:.2f}) {left_mark}",
            f"Right Knee (KL {right_pred}, conf {right_conf:.2f}) {right_mark}",
        ],
        out_path,
    )


if __name__ == "__main__":
    main()

# scripts/compare_knees_confidence.py
import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import matplotlib
matplotlib.use("Agg")

import torch
from torchvision import models, transforms
from PIL import Image
import numpy as np
from pathlib import Path

from src.explain.gradcam import GradCAM
from src.explain.viz_utils import overlay_heatmap, save_fig_grid


# -------------------------------------------------
# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (í•™ìŠµëœ KL ëª¨ë¸)
# -------------------------------------------------
def build_resnet50_trained(weight_path="outputs/resnet50_finetune_combined/model_best.pth"):
    print(f"âœ… Loading trained model from {weight_path}")
    model = models.resnet50(weights=None)
    model.fc = torch.nn.Linear(2048, 5)  # KL 0~4 = í´ë˜ìŠ¤ 5ê°œ

    state_dict = torch.load(weight_path, map_location="cpu")

    # âœ… 'backbone.' ì ‘ë‘ì–´ ì œê±°
    new_state_dict = {}
    for k, v in state_dict.items():
        new_k = k.replace("backbone.", "")
        new_state_dict[new_k] = v

    missing, unexpected = model.load_state_dict(new_state_dict, strict=False)
    print(f"â„¹ï¸ Missing keys: {len(missing)}, Unexpected keys: {len(unexpected)}")

    model.eval()
    return model


# -------------------------------------------------
# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜
# -------------------------------------------------
TR = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225)),
])


# -------------------------------------------------
# 3. ì¢Œ/ìš° ë¬´ë¦ ë¹„êµ + í™•ì‹ ë„ ë¶„ì„
# -------------------------------------------------
def main():
    left_path = "data/processed/train/2/9002411L.png"   # ì™¼ìª½ ë¬´ë¦
    right_path = "data/processed/train/2/9002411R.png"  # ì˜¤ë¥¸ìª½ ë¬´ë¦
    out_path = "outputs/vis/week5/compare_knees_conf.png"
    Path(out_path).parent.mkdir(parents=True, exist_ok=True)

    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        left_img = Image.open(left_path).convert("RGB")
        right_img = Image.open(right_path).convert("RGB")
    except FileNotFoundError:
        print("âŒ ì™¼ìª½ ë˜ëŠ” ì˜¤ë¥¸ìª½ ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì „ì²˜ë¦¬
    left_x = TR(left_img).unsqueeze(0)
    right_x = TR(right_img).unsqueeze(0)

    # ëª¨ë¸ ë° Grad-CAM ì„¤ì •
    model = build_resnet50_trained("outputs/resnet50_finetune_combined/model_best.pth")
    target_layer = model.layer4[-1]
    cam = GradCAM(model, target_layer)

    # -----------------------------------
    # ì˜ˆì¸¡ + í™•ì‹ ë„ ê³„ì‚°
    # -----------------------------------
    def predict_with_conf(x):
        with torch.no_grad():
            logits = model(x)
            probs = torch.softmax(logits, dim=1)
            conf, pred = probs.max(dim=1)
        try:
            cam_map, _ = cam(x)
        except Exception as e:
            print(f"âš ï¸ GradCAM ì˜¤ë¥˜ ë°œìƒ: {e}")
            cam_map = torch.zeros((1, 224, 224))
        return pred.item(), conf.item(), cam_map

    left_pred, left_conf, left_cam = predict_with_conf(left_x)
    right_pred, right_conf, right_cam = predict_with_conf(right_x)

    # -----------------------------------
    # í™•ì‹ ë„ ë“±ê¸‰ êµ¬ë¶„ (KOALA ê¸°ì¤€)
    # -----------------------------------
    def confidence_mark(conf):
        if conf >= 0.8:
            return "âœ… ì‹ ë¢° ë†’ìŒ"
        elif conf >= 0.6:
            return "âš ï¸ ì¤‘ê°„ (ì˜ì‹¬ ì˜ˆì¸¡)"
        else:
            return "âŒ ë‚®ìŒ (ì¬ê²€í†  í•„ìš”)"

    left_mark = confidence_mark(left_conf)
    right_mark = confidence_mark(right_conf)

    # -----------------------------------
    # ì¢Œ/ìš° ë¹„êµ ë¡œì§
    # -----------------------------------
    if left_pred > right_pred:
        compare_text = "ì™¼ìª½ ë¬´ë¦ì´ ë” ì†ìƒëœ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
    elif left_pred < right_pred:
        compare_text = "ì˜¤ë¥¸ìª½ ë¬´ë¦ì´ ë” ì†ìƒëœ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
    else:
        compare_text = "ì–‘ìª½ ë¬´ë¦ì˜ ì†ìƒ ì •ë„ê°€ ë¹„ìŠ·í•˜ê²Œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."

    # -----------------------------------
    # ì½˜ì†” ì¶œë ¥
    # -----------------------------------
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("ğŸ“Š ì¢Œìš° ë¬´ë¦ ë¹„êµ ê²°ê³¼")
    print(f"ì™¼ìª½ ì˜ˆì¸¡ ë“±ê¸‰: {left_pred} (í™•ì‹ ë„: {left_conf:.2f}) â†’ {left_mark}")
    print(f"ì˜¤ë¥¸ìª½ ì˜ˆì¸¡ ë“±ê¸‰: {right_pred} (í™•ì‹ ë„: {right_conf:.2f}) â†’ {right_mark}")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"ğŸ‘‰ {compare_text}")
    print(f"âœ… ì‹œê°í™” ê²°ê³¼ ì €ì¥: {out_path}")

    # -----------------------------------
    # ê²°ê³¼ ì €ì¥
    # -----------------------------------
    save_fig_grid(
        [
            overlay_heatmap(np.array(left_img.resize((224, 224))), left_cam.numpy()),
            overlay_heatmap(np.array(right_img.resize((224, 224))), right_cam.numpy()),
        ],
        [
            f"Left Knee (KL {left_pred}, conf {left_conf:.2f}) {left_mark}",
            f"Right Knee (KL {right_pred}, conf {right_conf:.2f}) {right_mark}",
        ],
        out_path,
    )


if __name__ == "__main__":
    main()
